{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assignment 2, Part 2, Implementation of Decision Tree using ID3 Algorithm\n"
     ]
    }
   ],
   "source": [
    "print(\"Assignment 2, Part 2, Implementation of Decision Tree using ID3 Algorithm\")\n",
    "#Authors\n",
    "#Meetika Sharma : MXS173530\n",
    "#Yash Pradhan : YPP170130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function: getTrainingDataset() to get the training dataset\n",
    "def getTrainingDataset():\n",
    "    import csv\n",
    "    with open(training_path, 'r') as instances:\n",
    "        myreader = csv.reader(instances)\n",
    "        #get header and data instances from the csv\n",
    "        headers = next(myreader, None)\n",
    "        training_examples = [list(map(int,rec)) for rec in csv.reader(instances, delimiter=',')]\n",
    "    #the last header is the class label, hence strip it\n",
    "    headers = headers[:-1]\n",
    "    \n",
    "    #print(\"Headers:\", headers)\n",
    "    #print(\"Training Examples:\", training_examples)\n",
    "    return training_examples, headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function: getTestingDataset() to get the testing dataset\n",
    "def getTestingDataset():\n",
    "    import csv\n",
    "    with open(testing_path, 'r') as instances:\n",
    "        myreader = csv.reader(instances)\n",
    "        #get header and data instances from the csv\n",
    "        headers = next(myreader, None)\n",
    "        testing_examples = [list(map(int,rec)) for rec in csv.reader(instances, delimiter=',')]\n",
    "    #the last header is the class label, hence strip it\n",
    "    headers = headers[:-1]\n",
    "    \n",
    "    #print(\"Headers:\", headers)\n",
    "    #print(\"Testing Examples:\", testing_examples)\n",
    "    return testing_examples, headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getValidationDataset():\n",
    "    import csv\n",
    "    with open(validation_path, 'r') as instances:\n",
    "        myreader = csv.reader(instances)\n",
    "        #get header and data instances from the csv\n",
    "        headers = next(myreader, None)\n",
    "        validation_examples = [list(map(int,rec)) for rec in csv.reader(instances, delimiter=',')]\n",
    "    #the last header is the class label, hence strip it\n",
    "    headers = headers[:-1]\n",
    "    \n",
    "    #print(\"Headers:\", headers)\n",
    "    #print(\"Testing Examples:\", testing_examples)\n",
    "    return validation_examples, headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We'll use the formula to find the Entropy\n",
    "def findEntropyAtNode(instances):\n",
    "    totalInstances = len(instances)\n",
    "    #keep a track of postive and negative labels\n",
    "    countClass = {}\n",
    "    for instance in instances:\n",
    "        currentClass = instance[-1]\n",
    "        if currentClass not in countClass.keys(): countClass[currentClass] = 0\n",
    "        countClass[currentClass] += 1\n",
    "    entropy = 0.0\n",
    "    for key in countClass:\n",
    "        probability = float(countClass[key])/totalInstances\n",
    "        entropy -= probability * log(probability, 2)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findBestAttribute(dataset):\n",
    "    totalFeatures = len(dataset[0]) - 1\n",
    "    parentEntropy = findEntropyAtNode(dataset)\n",
    "    maxInformationGain = 0.0\n",
    "    indexBestFeature = -1\n",
    "    \n",
    "    #iterate over all features to find the best feature\n",
    "    # i.e. the one with the maximum information gain\n",
    "    for i in range(totalFeatures):\n",
    "        featureList = [instance[i] for instance in dataset]\n",
    "        distinctValues = set(featureList)\n",
    "        entropy = 0.0\n",
    "        \n",
    "        #calculate the number of instances that belong to each class based on this attribute\n",
    "        for value in distinctValues:\n",
    "            subset = splitDataset(dataset, i, value)\n",
    "            probability = len(subset)/float(len(dataset))\n",
    "            entropy += probability * findEntropyAtNode(subset)\n",
    "        \n",
    "        informationGain = parentEntropy - entropy\n",
    "        \n",
    "        if(informationGain>maxInformationGain):\n",
    "            maxInformationGain = informationGain\n",
    "            indexBestFeature = i\n",
    "    return indexBestFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In one of the termination condition we label the node as the majority class\n",
    "#the following function returns majority class for current node\n",
    "def getMajorityClass(classList):\n",
    "    classCount = {}\n",
    "    for label in classList:\n",
    "        if label not in classCount.keys(): classCount[label] = 0\n",
    "        classCount[label] += 1\n",
    "        \n",
    "    #sort to get the class with max counts   \n",
    "    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedClassCount[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to split the dataset after finding the best attribute, strip the selected attribute axis\n",
    "def splitDataset(dataset, selectedAttribute, value):\n",
    "    retDataset = []\n",
    "    for instance in dataset:\n",
    "        if instance[selectedAttribute] == value:\n",
    "            subDataset = instance[:selectedAttribute]  # chop out axis used for splitting\n",
    "            subDataset.extend(instance[selectedAttribute + 1:])\n",
    "            retDataset.append(subDataset)\n",
    "    return retDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The ID3 Algotithm to generate decision tree\n",
    "def createTree(dataset,headers):\n",
    "    classList = [instance[-1] for instance in dataset]\n",
    "    \n",
    "    #splitting stops when all instances belong to the same class\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]  \n",
    "    #another criteria is that, there are no more attributes to split upon\n",
    "    if len(dataset[0]) == 1:  \n",
    "        return getMajorityClass(classList)\n",
    "    \n",
    "    #Finding the best attribute to split upon\n",
    "    bestFeat = findBestAttribute(dataset)\n",
    "    bestFeatLabel = headers[bestFeat]\n",
    "\n",
    "    #build a tree recursively\n",
    "    decisionTree = {bestFeatLabel: {}}\n",
    "    \n",
    "    del (headers[bestFeat])\n",
    "    \n",
    "    featValues = [instance[bestFeat] for instance in dataset]\n",
    "    uniqueVals = set(featValues)\n",
    "    \n",
    "    for value in uniqueVals:\n",
    "        subHeaders = headers[:]  \n",
    "        decisionTree[bestFeatLabel][value] = createTree(splitDataset(dataset, bestFeat, value), subHeaders)\n",
    "        decisionTree[bestFeatLabel]['majority_class'] = int(getMajorityClass(classList))\n",
    "        \n",
    "    return decisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#classify an instance\n",
    "def classify(inputTree, featureLabels, instanceVector):\n",
    "    #print(\"Let's classify\", instanceVector)\n",
    "    \n",
    "    # find the attribute on which split has been performed\n",
    "    for key in inputTree:\n",
    "        #print (\"key: \"+ key +\", value: \"+str(inputTree[key]))\n",
    "        #print(\"Current Splitting Attribute:\", key)\n",
    "        innerpart = inputTree[key]\n",
    "        #print(\"Inner Part:\", str(innerpart))\n",
    "    \n",
    "    # find the value that this instance holds for the splitting attribute\n",
    "    index = featureLabels.index(key)\n",
    "    #print(\"Index of attribute\", key, \"is \", index)\n",
    "    value = instanceVector[index]\n",
    "    #print(\"Value for attribute\", key, \"is \", value)\n",
    "    \n",
    "    innervalue = innerpart[value]\n",
    "    #print(innervalue)\n",
    "    # In the tree find what holds for Attribute Ai and its corresponding value of instance\n",
    "    \n",
    "    # If there is a node further on, apply recursively till you reach the root node\n",
    "    if isinstance(innervalue, dict):\n",
    "        #print(innervalue)\n",
    "        classLabel = classify(innervalue, featureLabels, instanceVector)\n",
    "    else:\n",
    "    # If it is a class label, it means we have reached the root node and hence ready for prediction\n",
    "    # the class label is the prediction, return it to the driver function\n",
    "        classLabel = innervalue\n",
    "    \n",
    "    return classLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getting accuracy on data\n",
    "def calculateAccuracy(decisiontree, dataset, labels):\n",
    "    total_instances = len(dataset)\n",
    "    num_correct_predictions = 0\n",
    "    \n",
    "    for instance in dataset:\n",
    "        predicted_class_label = classify(decisiontree, labels, instance[:-1])\n",
    "        if(predicted_class_label == instance[-1]):\n",
    "            num_correct_predictions += 1\n",
    "            \n",
    "    accuracy = num_correct_predictions/total_instances\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print the tree\n",
    "def printTree(tree, d=0):\n",
    "    for attribute in tree:\n",
    "        options = tree[attribute]\n",
    "        for values in options:\n",
    "            subtree = options[values]\n",
    "            if(isinstance(subtree, dict)):\n",
    "                print(\" |\" * d,attribute, \"=\", values, \":\")\n",
    "                printTree(subtree, d+1)\n",
    "            else:\n",
    "                if(values!='majority_class'):\n",
    "                    print(\" |\" * d,attribute, \"=\", values, \":\", subtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPrunedTree(tree):\n",
    "    #pruning logic yet to be implemented\n",
    "    pruned_tree = tree\n",
    "    return pruned_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTotalNodes(tree):\n",
    "    str_tree = str(tree)\n",
    "    return str_tree.count(\"{\") + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNumLeaves(tree):\n",
    "    N = getTotalNodes(tree)\n",
    "    return (N+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter path of training data set: training_set.csv\n",
      "Enter path of testing data set: test_set.csv\n",
      "Enter path of validation data set: validation_set.csv\n",
      "Enter pruning factor: 0.1\n"
     ]
    }
   ],
   "source": [
    "#get input from user\n",
    "training_path = input(\"Enter path of training data set: \")\n",
    "testing_path = input(\"Enter path of testing data set: \")\n",
    "validation_path = input(\"Enter path of validation data set: \")\n",
    "pruning_factor = input(\"Enter pruning factor: \")\n",
    "    \n",
    "# collect data\n",
    "dataset, headers = getTrainingDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree generated by ID3 Algo.\n",
      " XO = 0 :\n",
      " | XM = 0 :\n",
      " | | XF = 0 :\n",
      " | | | XB = 0 :\n",
      " | | | | XG = 0 : 0\n",
      " | | | | XG = 1 :\n",
      " | | | | | XD = 0 :\n",
      " | | | | | | XS = 0 : 0\n",
      " | | | | | | XS = 1 :\n",
      " | | | | | | | XC = 0 : 1\n",
      " | | | | | | | XC = 1 :\n",
      " | | | | | | | | XH = 0 : 0\n",
      " | | | | | | | | XH = 1 : 1\n",
      " | | | | | XD = 1 :\n",
      " | | | | | | XE = 0 : 0\n",
      " | | | | | | XE = 1 :\n",
      " | | | | | | | XK = 0 : 0\n",
      " | | | | | | | XK = 1 : 1\n",
      " | | | XB = 1 :\n",
      " | | | | XD = 0 : 0\n",
      " | | | | XD = 1 :\n",
      " | | | | | XI = 0 : 0\n",
      " | | | | | XI = 1 :\n",
      " | | | | | | XG = 0 : 1\n",
      " | | | | | | XG = 1 : 0\n",
      " | | XF = 1 : 0\n",
      " | XM = 1 :\n",
      " | | XB = 0 :\n",
      " | | | XD = 0 :\n",
      " | | | | XG = 0 :\n",
      " | | | | | XF = 0 : 0\n",
      " | | | | | XF = 1 :\n",
      " | | | | | | XJ = 0 :\n",
      " | | | | | | | XN = 0 : 1\n",
      " | | | | | | | XN = 1 :\n",
      " | | | | | | | | XE = 0 :\n",
      " | | | | | | | | | XK = 0 : 0\n",
      " | | | | | | | | | XK = 1 : 1\n",
      " | | | | | | | | XE = 1 : 0\n",
      " | | | | | | XJ = 1 :\n",
      " | | | | | | | XC = 0 :\n",
      " | | | | | | | | XT = 0 :\n",
      " | | | | | | | | | XL = 0 :\n",
      " | | | | | | | | | | XE = 0 :\n",
      " | | | | | | | | | | | XI = 0 : 0\n",
      " | | | | | | | | | | | XI = 1 : 1\n",
      " | | | | | | | | | | XE = 1 : 1\n",
      " | | | | | | | | | XL = 1 : 0\n",
      " | | | | | | | | XT = 1 : 1\n",
      " | | | | | | | XC = 1 : 1\n",
      " | | | | XG = 1 :\n",
      " | | | | | XU = 0 : 1\n",
      " | | | | | XU = 1 :\n",
      " | | | | | | XI = 0 : 0\n",
      " | | | | | | XI = 1 : 1\n",
      " | | | XD = 1 :\n",
      " | | | | XC = 0 :\n",
      " | | | | | XF = 0 :\n",
      " | | | | | | XG = 0 : 0\n",
      " | | | | | | XG = 1 :\n",
      " | | | | | | | XP = 0 :\n",
      " | | | | | | | | XS = 0 : 0\n",
      " | | | | | | | | XS = 1 : 1\n",
      " | | | | | | | XP = 1 : 0\n",
      " | | | | | XF = 1 :\n",
      " | | | | | | XJ = 0 : 1\n",
      " | | | | | | XJ = 1 :\n",
      " | | | | | | | XE = 0 :\n",
      " | | | | | | | | XG = 0 :\n",
      " | | | | | | | | | XI = 0 : 1\n",
      " | | | | | | | | | XI = 1 : 0\n",
      " | | | | | | | | XG = 1 : 0\n",
      " | | | | | | | XE = 1 :\n",
      " | | | | | | | | XT = 0 :\n",
      " | | | | | | | | | XG = 0 : 1\n",
      " | | | | | | | | | XG = 1 : 0\n",
      " | | | | | | | | XT = 1 : 1\n",
      " | | | | XC = 1 : 0\n",
      " | | XB = 1 :\n",
      " | | | XI = 0 : 0\n",
      " | | | XI = 1 :\n",
      " | | | | XC = 0 :\n",
      " | | | | | XK = 0 :\n",
      " | | | | | | XP = 0 : 1\n",
      " | | | | | | XP = 1 :\n",
      " | | | | | | | XS = 0 :\n",
      " | | | | | | | | XG = 0 : 1\n",
      " | | | | | | | | XG = 1 :\n",
      " | | | | | | | | | XF = 0 : 0\n",
      " | | | | | | | | | XF = 1 : 1\n",
      " | | | | | | | XS = 1 : 0\n",
      " | | | | | XK = 1 : 0\n",
      " | | | | XC = 1 : 0\n",
      " XO = 1 :\n",
      " | XI = 0 :\n",
      " | | XM = 0 :\n",
      " | | | XQ = 0 :\n",
      " | | | | XF = 0 :\n",
      " | | | | | XH = 0 :\n",
      " | | | | | | XB = 0 : 0\n",
      " | | | | | | XB = 1 :\n",
      " | | | | | | | XC = 0 : 1\n",
      " | | | | | | | XC = 1 : 0\n",
      " | | | | | XH = 1 : 1\n",
      " | | | | XF = 1 : 0\n",
      " | | | XQ = 1 :\n",
      " | | | | XJ = 0 :\n",
      " | | | | | XN = 0 :\n",
      " | | | | | | XP = 0 : 1\n",
      " | | | | | | XP = 1 :\n",
      " | | | | | | | XB = 0 :\n",
      " | | | | | | | | XF = 0 : 0\n",
      " | | | | | | | | XF = 1 : 1\n",
      " | | | | | | | XB = 1 : 0\n",
      " | | | | | XN = 1 : 0\n",
      " | | | | XJ = 1 :\n",
      " | | | | | XL = 0 :\n",
      " | | | | | | XH = 0 : 0\n",
      " | | | | | | XH = 1 :\n",
      " | | | | | | | XK = 0 :\n",
      " | | | | | | | | XU = 0 : 1\n",
      " | | | | | | | | XU = 1 : 0\n",
      " | | | | | | | XK = 1 : 1\n",
      " | | | | | XL = 1 : 1\n",
      " | | XM = 1 :\n",
      " | | | XQ = 0 :\n",
      " | | | | XF = 0 :\n",
      " | | | | | XL = 0 :\n",
      " | | | | | | XC = 0 : 1\n",
      " | | | | | | XC = 1 :\n",
      " | | | | | | | XH = 0 : 1\n",
      " | | | | | | | XH = 1 :\n",
      " | | | | | | | | XU = 0 :\n",
      " | | | | | | | | | XB = 0 :\n",
      " | | | | | | | | | | XD = 0 : 1\n",
      " | | | | | | | | | | XD = 1 : 0\n",
      " | | | | | | | | | XB = 1 : 0\n",
      " | | | | | | | | XU = 1 : 1\n",
      " | | | | | XL = 1 :\n",
      " | | | | | | XC = 0 :\n",
      " | | | | | | | XB = 0 : 0\n",
      " | | | | | | | XB = 1 :\n",
      " | | | | | | | | XP = 0 : 0\n",
      " | | | | | | | | XP = 1 : 1\n",
      " | | | | | | XC = 1 : 1\n",
      " | | | | XF = 1 : 0\n",
      " | | | XQ = 1 : 0\n",
      " | XI = 1 :\n",
      " | | XT = 0 :\n",
      " | | | XH = 0 :\n",
      " | | | | XP = 0 :\n",
      " | | | | | XF = 0 : 0\n",
      " | | | | | XF = 1 :\n",
      " | | | | | | XQ = 0 :\n",
      " | | | | | | | XK = 0 : 1\n",
      " | | | | | | | XK = 1 :\n",
      " | | | | | | | | XC = 0 : 0\n",
      " | | | | | | | | XC = 1 : 1\n",
      " | | | | | | XQ = 1 :\n",
      " | | | | | | | XK = 0 : 0\n",
      " | | | | | | | XK = 1 : 1\n",
      " | | | | XP = 1 :\n",
      " | | | | | XS = 0 :\n",
      " | | | | | | XD = 0 :\n",
      " | | | | | | | XC = 0 :\n",
      " | | | | | | | | XJ = 0 :\n",
      " | | | | | | | | | XN = 0 : 0\n",
      " | | | | | | | | | XN = 1 : 1\n",
      " | | | | | | | | XJ = 1 :\n",
      " | | | | | | | | | XB = 0 : 0\n",
      " | | | | | | | | | XB = 1 :\n",
      " | | | | | | | | | | XG = 0 : 1\n",
      " | | | | | | | | | | XG = 1 : 0\n",
      " | | | | | | | XC = 1 : 0\n",
      " | | | | | | XD = 1 :\n",
      " | | | | | | | XM = 0 :\n",
      " | | | | | | | | XC = 0 : 1\n",
      " | | | | | | | | XC = 1 : 0\n",
      " | | | | | | | XM = 1 : 1\n",
      " | | | | | XS = 1 : 1\n",
      " | | | XH = 1 :\n",
      " | | | | XJ = 0 :\n",
      " | | | | | XC = 0 :\n",
      " | | | | | | XN = 0 : 1\n",
      " | | | | | | XN = 1 :\n",
      " | | | | | | | XF = 0 :\n",
      " | | | | | | | | XG = 0 : 1\n",
      " | | | | | | | | XG = 1 : 0\n",
      " | | | | | | | XF = 1 : 0\n",
      " | | | | | XC = 1 :\n",
      " | | | | | | XM = 0 : 0\n",
      " | | | | | | XM = 1 :\n",
      " | | | | | | | XF = 0 :\n",
      " | | | | | | | | XR = 0 : 1\n",
      " | | | | | | | | XR = 1 : 0\n",
      " | | | | | | | XF = 1 : 1\n",
      " | | | | XJ = 1 :\n",
      " | | | | | XS = 0 : 1\n",
      " | | | | | XS = 1 :\n",
      " | | | | | | XG = 0 :\n",
      " | | | | | | | XB = 0 : 0\n",
      " | | | | | | | XB = 1 :\n",
      " | | | | | | | | XD = 0 : 1\n",
      " | | | | | | | | XD = 1 :\n",
      " | | | | | | | | | XE = 0 : 0\n",
      " | | | | | | | | | XE = 1 : 1\n",
      " | | | | | | XG = 1 :\n",
      " | | | | | | | XC = 0 : 1\n",
      " | | | | | | | XC = 1 :\n",
      " | | | | | | | | XD = 0 : 1\n",
      " | | | | | | | | XD = 1 : 0\n",
      " | | XT = 1 :\n",
      " | | | XS = 0 :\n",
      " | | | | XQ = 0 :\n",
      " | | | | | XK = 0 :\n",
      " | | | | | | XC = 0 :\n",
      " | | | | | | | XR = 0 :\n",
      " | | | | | | | | XH = 0 :\n",
      " | | | | | | | | | XE = 0 : 0\n",
      " | | | | | | | | | XE = 1 : 1\n",
      " | | | | | | | | XH = 1 : 1\n",
      " | | | | | | | XR = 1 :\n",
      " | | | | | | | | XB = 0 :\n",
      " | | | | | | | | | XD = 0 : 0\n",
      " | | | | | | | | | XD = 1 : 1\n",
      " | | | | | | | | XB = 1 : 0\n",
      " | | | | | | XC = 1 : 1\n",
      " | | | | | XK = 1 :\n",
      " | | | | | | XD = 0 :\n",
      " | | | | | | | XF = 0 : 0\n",
      " | | | | | | | XF = 1 : 1\n",
      " | | | | | | XD = 1 : 0\n",
      " | | | | XQ = 1 :\n",
      " | | | | | XM = 0 :\n",
      " | | | | | | XN = 0 :\n",
      " | | | | | | | XU = 0 : 1\n",
      " | | | | | | | XU = 1 : 0\n",
      " | | | | | | XN = 1 :\n",
      " | | | | | | | XP = 0 :\n",
      " | | | | | | | | XB = 0 :\n",
      " | | | | | | | | | XF = 0 : 0\n",
      " | | | | | | | | | XF = 1 : 1\n",
      " | | | | | | | | XB = 1 : 1\n",
      " | | | | | | | XP = 1 : 1\n",
      " | | | | | XM = 1 : 0\n",
      " | | | XS = 1 :\n",
      " | | | | XL = 0 :\n",
      " | | | | | XD = 0 :\n",
      " | | | | | | XU = 0 : 1\n",
      " | | | | | | XU = 1 :\n",
      " | | | | | | | XB = 0 :\n",
      " | | | | | | | | XE = 0 : 1\n",
      " | | | | | | | | XE = 1 :\n",
      " | | | | | | | | | XC = 0 : 1\n",
      " | | | | | | | | | XC = 1 : 0\n",
      " | | | | | | | XB = 1 :\n",
      " | | | | | | | | XG = 0 :\n",
      " | | | | | | | | | XH = 0 : 0\n",
      " | | | | | | | | | XH = 1 : 1\n",
      " | | | | | | | | XG = 1 : 0\n",
      " | | | | | XD = 1 :\n",
      " | | | | | | XG = 0 : 0\n",
      " | | | | | | XG = 1 : 1\n",
      " | | | | XL = 1 :\n",
      " | | | | | XH = 0 :\n",
      " | | | | | | XD = 0 :\n",
      " | | | | | | | XQ = 0 : 0\n",
      " | | | | | | | XQ = 1 :\n",
      " | | | | | | | | XB = 0 : 0\n",
      " | | | | | | | | XB = 1 : 1\n",
      " | | | | | | XD = 1 :\n",
      " | | | | | | | XB = 0 : 1\n",
      " | | | | | | | XB = 1 : 0\n",
      " | | | | | XH = 1 : 0\n"
     ]
    }
   ],
   "source": [
    "#build the decision tree\n",
    "decisiontree = createTree(dataset, headers)\n",
    "print(\"Decision Tree generated by ID3 Algo.\")\n",
    "printTree(decisiontree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre Pruned Accuracy\n",
      "-------------------------\n",
      "Number of training instances = 600\n",
      "Number of training attributes = 20\n",
      "Total number of nodes in the tree = 275\n",
      "Total number of leaf nodes in the tree = 138.0\n",
      "Accuracy of the model on the training dataset = 100.0\n",
      "\n",
      "Number of validation instances = 2000\n",
      "Number of validation attributes = 20\n",
      "Accuracy of the model on the validation dataset before pruning =  75.9\n",
      "\n",
      "Number of testing instances = 2000\n",
      "Number of testing attributes = 20\n",
      "Accuracy of the model on the testing dataset = 75.85\n"
     ]
    }
   ],
   "source": [
    "training_dataset, training_headers = getTrainingDataset()\n",
    "training_accuracy = calculateAccuracy(decisiontree, training_dataset, training_headers)\n",
    "\n",
    "testing_dataset, testing_headers = getTestingDataset()\n",
    "testing_accuracy = calculateAccuracy(decisiontree, testing_dataset, testing_headers)\n",
    "\n",
    "validation_dataset, validation_headers = getValidationDataset()\n",
    "validation_accuracy = calculateAccuracy(decisiontree, validation_dataset, validation_headers)\n",
    "\n",
    "print(\"Pre Pruned Accuracy\")\n",
    "print('-'*25)\n",
    "print(\"Number of training instances =\", len(training_dataset))\n",
    "print(\"Number of training attributes =\", len(training_headers))\n",
    "\n",
    "print(\"Total number of nodes in the tree =\", getTotalNodes(decisiontree))\n",
    "print(\"Total number of leaf nodes in the tree =\", getNumLeaves(decisiontree))\n",
    "print(\"Accuracy of the model on the training dataset =\", training_accuracy*100)\n",
    "\n",
    "print(\"\\nNumber of validation instances =\", len(validation_dataset))\n",
    "print(\"Number of validation attributes =\", len(validation_headers))\n",
    "print(\"Accuracy of the model on the validation dataset before pruning = \", validation_accuracy*100)\n",
    "\n",
    "print(\"\\nNumber of testing instances =\", len(testing_dataset))\n",
    "print(\"Number of testing attributes =\", len(testing_headers))\n",
    "print(\"Accuracy of the model on the testing dataset =\", testing_accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Pruned Accuracy\n",
      "-------------------------\n",
      "Number of training instances = 600\n",
      "Number of training attributes = 20\n",
      "Total number of nodes in the tree = 275\n",
      "Total number of leaf nodes in the tree = 138.0\n",
      "Accuracy of the model on the training dataset = 100.0\n",
      "\n",
      "Number of validation instances = 2000\n",
      "Number of validation attributes = 20\n",
      "Accuracy of the model on the validation dataset before pruning =  75.9\n",
      "\n",
      "Number of testing instances = 2000\n",
      "Number of testing attributes = 20\n",
      "Accuracy of the model on the testing dataset = 75.85\n"
     ]
    }
   ],
   "source": [
    "#Pruning the tree\n",
    "prunedtree = getPrunedTree(decisiontree)\n",
    "\n",
    "training_accuracy = calculateAccuracy(decisiontree, training_dataset, training_headers)\n",
    "testing_accuracy = calculateAccuracy(decisiontree, testing_dataset, testing_headers)\n",
    "validation_accuracy = calculateAccuracy(decisiontree, validation_dataset, validation_headers)\n",
    "\n",
    "print(\"Post Pruned Accuracy\")\n",
    "print('-'*25)\n",
    "print(\"Number of training instances =\", len(training_dataset))\n",
    "print(\"Number of training attributes =\", len(training_headers))\n",
    "\n",
    "print(\"Total number of nodes in the tree =\", getTotalNodes(decisiontree))\n",
    "print(\"Total number of leaf nodes in the tree =\", getNumLeaves(decisiontree))\n",
    "print(\"Accuracy of the model on the training dataset =\", training_accuracy*100)\n",
    "\n",
    "print(\"\\nNumber of validation instances =\", len(validation_dataset))\n",
    "print(\"Number of validation attributes =\", len(validation_headers))\n",
    "print(\"Accuracy of the model on the validation dataset before pruning = \", validation_accuracy*100)\n",
    "\n",
    "print(\"\\nNumber of testing instances =\", len(testing_dataset))\n",
    "print(\"Number of testing attributes =\", len(testing_headers))\n",
    "print(\"Accuracy of the model on the testing dataset =\", testing_accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
